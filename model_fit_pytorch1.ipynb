{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple nn model fitting\n",
    "\n",
    "Notebook will run a very simple nn on the training points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import librosa\n",
    "# import librosa.display\n",
    "# import sklearn as skl\n",
    "# import sklearn.utils\n",
    "# import IPython.display as ipd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import ast\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define network class\n",
    "#used some help from https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size = 1):\n",
    "        super(Net, self).__init__()\n",
    "        #linear layers to keep decrease the number of nodes\n",
    "        self.layer1 = nn.Linear(input_size, int(input_size/2))\n",
    "        self.layer2 = nn.Linear(int(input_size/2), int(input_size/4))\n",
    "        self.layer3 = nn.Linear(int(input_size/4), int(input_size/8))\n",
    "        self.layer4 = nn.Linear(int(input_size/8), int(input_size/16))\n",
    "        self.last = nn.Linear(int(input_size/16), output_size)\n",
    "\n",
    "    # x represents our data\n",
    "    def forward(self, x):\n",
    "        #these are a bunch of linear layers with relu activation\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = F.relu(self.layer4(x))\n",
    "        x = self.last(x)\n",
    "        return x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_dim =  1000\n",
      "n_training_points =  50\n",
      "n_dim =  1000\n",
      "n_training_points =  25\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0077, -0.1812, -0.1608,  ...,  0.2518,  0.1378,  0.1512],\n",
      "        [-0.0131, -0.1836, -0.1614,  ...,  0.2579,  0.1327,  0.1578],\n",
      "        [-0.0178, -0.1850, -0.1577,  ...,  0.2488,  0.1278,  0.1573]])\n",
      "1\n",
      "torch.Size([50, 18])\n",
      "torch.Size([25, 18])\n"
     ]
    }
   ],
   "source": [
    "#import training data\n",
    "train_data = torch.tensor(np.load('data/train_data.npy').T).float()[:1000]\n",
    "labels = torch.tensor(np.load('data/train_labels.npy')).float()\n",
    "n_dim, n_training_points = train_data.shape\n",
    "print(\"n_dim = \", n_dim)\n",
    "print('n_training_points = ', n_training_points )\n",
    "\n",
    "#get testing data\n",
    "test_data = torch.tensor(np.load('data/test_data.npy').T).float()[:1000]\n",
    "test_labels = torch.tensor(np.load('data/test_labels.npy')).float()\n",
    "_, n_testing_points = test_data.shape\n",
    "print(\"n_dim = \", n_dim)\n",
    "print('n_training_points = ', n_testing_points )\n",
    "print(test_data)\n",
    "\n",
    "\n",
    "#one hot encode the genre labels\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(torch.cat((labels, test_labels)).unsqueeze(1)) #takes a 2d array as input and labels is 1d; need labels for all training and testing points\n",
    "print(len(enc.categories_))\n",
    "labels = enc.transform(labels.unsqueeze(1)).toarray()\n",
    "labels = torch.tensor(labels).float()\n",
    "print(labels.shape)\n",
    "_, n_categories = labels.shape #number of categories is out output size for our network\n",
    "\n",
    "\n",
    "#encode testing labels\n",
    "test_labels = enc.transform(test_labels.unsqueeze(1)).toarray()\n",
    "test_labels = torch.tensor(test_labels).float()\n",
    "print(test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Linear(in_features=1000, out_features=500, bias=True)\n",
      "  (layer2): Linear(in_features=500, out_features=250, bias=True)\n",
      "  (layer3): Linear(in_features=250, out_features=125, bias=True)\n",
      "  (layer4): Linear(in_features=125, out_features=62, bias=True)\n",
      "  (last): Linear(in_features=62, out_features=18, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#define the model, optimizer and loss function\n",
    "model = Net(n_dim, n_categories)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters()) #adam is a \"better\" version of stochastic gradient decent\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved at epoch  0\n",
      "loss =  tensor(0.0648, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0573, grad_fn=<MseLossBackward>)\n",
      "model saved at epoch  1\n",
      "loss =  tensor(0.0625, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0564, grad_fn=<MseLossBackward>)\n",
      "model saved at epoch  2\n",
      "loss =  tensor(0.0604, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0557, grad_fn=<MseLossBackward>)\n",
      "model saved at epoch  3\n",
      "loss =  tensor(0.0583, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0550, grad_fn=<MseLossBackward>)\n",
      "model saved at epoch  4\n",
      "loss =  tensor(0.0562, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0545, grad_fn=<MseLossBackward>)\n",
      "model saved at epoch  5\n",
      "loss =  tensor(0.0540, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0542, grad_fn=<MseLossBackward>)\n",
      "model saved at epoch  6\n",
      "loss =  tensor(0.0516, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0542, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0493, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0543, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0470, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0547, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0449, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0554, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0429, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0562, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0411, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0574, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0395, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0587, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0379, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0601, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0365, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0616, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0352, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0631, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0339, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0650, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0328, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0674, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0317, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0704, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0308, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0740, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0301, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0783, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0295, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0826, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0290, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0863, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0286, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0889, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0281, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0903, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0276, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0904, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0270, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0897, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0265, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0888, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0261, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0881, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0257, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0877, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0254, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0879, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0251, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0887, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0247, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0903, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0244, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0925, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0240, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0947, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0236, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0967, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0233, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.0986, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0230, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1005, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0227, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1022, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0224, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1031, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0222, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1032, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0219, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1036, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0217, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1047, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0214, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1062, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0212, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1075, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0209, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1083, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0207, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1089, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0204, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1094, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0202, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1098, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0199, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1099, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0197, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1104, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0194, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1116, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0192, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1131, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0189, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1139, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0187, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1146, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0184, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1152, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0182, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1152, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0179, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1158, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0176, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1161, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0173, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1154, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0171, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1151, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0168, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1152, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0165, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1148, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0162, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1143, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0159, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1136, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0156, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1125, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0153, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1121, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0151, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1120, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0148, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1125, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0145, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1120, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0144, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1141, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0141, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1108, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0138, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1142, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0135, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1113, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0133, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1106, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0130, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1134, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(0.0128, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1137, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0125, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1135, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0123, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1137, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0120, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1143, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0118, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1165, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0116, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1170, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0114, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1170, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0111, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1182, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0110, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1196, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0107, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1207, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0106, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1214, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0103, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1227, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0102, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1251, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0100, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1270, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0098, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1289, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0097, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1298, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0095, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1334, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0096, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1334, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0094, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1402, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0091, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1378, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0089, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1404, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0089, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1475, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0087, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1459, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0085, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1496, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0084, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1536, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0083, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1518, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0081, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1572, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0080, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1638, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0079, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1615, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0078, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1644, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0077, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1711, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0076, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1710, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0074, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1727, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0074, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1774, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0073, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1773, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0071, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1822, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0070, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1847, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0070, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1837, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0069, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1904, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0068, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1905, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0067, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1907, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0066, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1953, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0065, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1963, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0064, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1969, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0064, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2034, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0064, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1978, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0064, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2072, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0062, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2017, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0061, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2013, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0061, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2068, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0060, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2027, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0059, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2081, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0059, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2051, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0058, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2037, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0057, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2067, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0057, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2045, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0056, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2075, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0055, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2035, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0055, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2075, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0054, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2050, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0053, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2067, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0053, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2080, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0052, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2044, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0052, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2085, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0052, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2052, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0052, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2082, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0052, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2018, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0050, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2097, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0050, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2020, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0049, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2047, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0049, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2087, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0049, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2012, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0048, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2073, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0047, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2032, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0046, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2041, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0046, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2045, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0047, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1994, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0047, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2069, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(0.0046, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1971, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0045, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2014, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0044, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2000, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0044, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2001, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0044, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2030, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0043, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1970, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0042, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2008, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0042, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1984, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0041, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1989, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0041, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.2000, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0041, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1961, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0041, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1998, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0041, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1947, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0041, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1988, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0041, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1928, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0040, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1995, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0039, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1952, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0038, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1975, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0038, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1960, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0038, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1947, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0038, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1978, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0038, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1902, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0038, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1970, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0037, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1916, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0037, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1961, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0036, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1922, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0035, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1950, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0035, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1943, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0035, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1904, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0035, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1970, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0035, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1891, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0034, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1941, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0034, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1911, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0033, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1924, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0033, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1931, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0033, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1925, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0032, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1931, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0032, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1914, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0033, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1949, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0033, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1903, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0033, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1951, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0034, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1887, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0033, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1958, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0032, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1883, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0031, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1936, grad_fn=<MseLossBackward>)\n",
      "loss =  tensor(0.0031, grad_fn=<MseLossBackward>) : test_loss =  tensor(0.1940, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 200\n",
    "max_test_loss = 1e10\n",
    "for epoch in range(max_epochs):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = model(train_data.T)#put through model\n",
    "    loss = criterion(output, labels)#find loss\n",
    "    test_output = model(test_data.T) \n",
    "    test_loss = criterion(test_output, test_labels)\n",
    "    if(test_loss< max_test_loss):\n",
    "        max_test_loss = test_loss\n",
    "        torch.save(model, \"model.pt\")\n",
    "        print(\"model saved at epoch \", epoch)\n",
    "    loss.backward() #do the back propogation\n",
    "    optimizer.step()    # Does the update\n",
    "    \n",
    "    print(\"loss = \", loss, \": test_loss = \", test_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss =  tensor(0.0516, grad_fn=<MseLossBackward>)\n",
      "percent predicted correctly is  16.0 %\n"
     ]
    }
   ],
   "source": [
    "#find the classification error of the training data \n",
    "count = 0\n",
    "\n",
    "output = model(train_data.T)\n",
    "loss = criterion(output, labels)\n",
    "print(\" loss = \", loss)\n",
    "#count number predicted correctly\n",
    "for i in range(len(output)):\n",
    "    idx_output = torch.argmax(output[i])\n",
    "    idx_truth = torch.argmax(labels[i])\n",
    "    if idx_output == idx_truth:\n",
    "        count += 1\n",
    "    else:\n",
    "        pass #do nothing if not equal\n",
    "print(\"percent predicted correctly is \", 100*count/len(output), '%')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss =  tensor(0.0542, grad_fn=<MseLossBackward>)\n",
      "percent predicted correctly is  2.0 %\n"
     ]
    }
   ],
   "source": [
    "#find the classification of the test data\n",
    "count = 0\n",
    "test_output = model(test_data.T)\n",
    "test_loss = criterion(test_output, test_labels)\n",
    "print(\"test loss = \", test_loss)\n",
    "#count number predicted correctly\n",
    "for i in range(len(test_output)):\n",
    "    idx_output = torch.argmax(test_output[i])\n",
    "    idx_truth = torch.argmax(test_labels[i])\n",
    "#     print(\"idx_output = \", idx_output, \": idx_truth = \", idx_truth)\n",
    "    if idx_output == idx_truth:\n",
    "        count += 1\n",
    "    else:\n",
    "        pass #do nothing if not equal\n",
    "print(\"percent predicted correctly is \", 100*count/len(output), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
